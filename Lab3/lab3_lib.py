
# lab3_lib.py
# Include some global var
from __future__ import unicode_literals, print_function, division
from io import open
import pickle
import unicodedata
import string
import re
import random
import time
import math
import torch
import torch.nn as nn
from torch import optim
import torch.nn.functional as F
from torch.autograd import Variable
import matplotlib.pyplot as plt
import sys
import matplotlib.ticker as ticker
import numpy as np
from os import system
from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu
import os



device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# for a-z use 0-25
SOS_token = 26
EOS_token = 27
#----------Hyper Parameters----------#
hidden_size = 256
latent_size = 32
condition_size = 8

#The number of vocabulary
empty_input_ratio = 0.1

vocab_size = 28
teacher_forcing_ratio = 0.5 
KLD_weight = 0.0
LR = 0.05

#About human reading to tensor
num_tense = 4
alpha2num = {}
num2alpha = {}
n_words = 0
tokens = ["SOS", "EOS"]
alphabet = list('abcdefghijklmnopqrstuvwxyz')
index = 0
for tok in alphabet + tokens :
    alpha2num[ tok ] = index
    num2alpha[ index ] = tok
    index += 1


def cond2tensor(cond):
    #cond is int
    onehot = [0,0,0,0]
    onehot[cond] = 1
    return torch.LongTensor(onehot)
    
def lookup(varname , x , content=False,flag = True):
    try:
        print(varname , ':' , x.shape, end=' ')
    except:
        print(varname , ':' , x, end=' ')
    if content:
        print(x)
    else:
        print()


def str2tensor(s):
    s = list(s) + ["EOS"]
    return torch.LongTensor([alpha2num[tok] for tok in s]).to(device)



################################
#Example inputs of compute_bleu
################################
#The target word
#reference = 'accessed'
#The word generated by your model
#output = 'access'
#compute BLEU-4 score
def compute_bleu(output, reference):
    cc = SmoothingFunction()
    return sentence_bleu([reference], output,weights=(0.25, 0.25, 0.25, 0.25),smoothing_function=cc.method1)


"""============================================================================
example input of Gaussian_score

words = [['consult', 'consults', 'consulting', 'consulted'],
['plead', 'pleads', 'pleading', 'pleaded'],
['explain', 'explains', 'explaining', 'explained'],
['amuse', 'amuses', 'amusing', 'amused'], ....]

the order should be : simple present, third person, present progressive, past
============================================================================"""

def Gaussian_score(words):
    words_list = []
    score = 0
    yourpath = './train.txt'
    with open(yourpath,'r') as fp:
        for line in fp:
            word = line.split(' ')
            word[3] = word[3].strip('\n')
            words_list.extend([word])
        for t in words:
            for i in words_list:
                if t == i:
                    score += 1
    return score/len(words)

def asMinutes(s):
    m = math.floor(s / 60)
    s -= m * 60
    return '%dm %ds' % (m, s)

def timeSince(since):
    now = time.time()
    s = now - since
    return '%s ' % (asMinutes(s))


def KLDW(iter, method = ''):
    return 0
    if method == 'M': #Monotonic
        slope = 0.000001
        w = iter * slope
        if w > 0.01:
            w = 0.01
        return w
    elif method == 'C': #Cyclical
        slope = 0.001
        scope = 10
        w = (iter % scope) * slope
        if w > 0.01:
            w = 0.01
        return w

def KL_loss(m, logvar):
    return torch.sum(0.5 * (-logvar + (m**2) + torch.exp(logvar) - 1))

def T_F_R(iter, maxiter):
    return (maxiter-iter)/maxiter


def save_cvae(cvae, dir = './cvae_best'):
    save_model(cvae, dir, 'cvae')
    save_model(cvae.E, dir, 'E')
    save_model(cvae.D, dir, 'D')
    save_model(cvae.R, dir, 'R')


def load_cvae(cvae, dir = './cvae_best'):
    load_model(cvae, dir, 'cvae')
    load_model(cvae.E, dir, 'E')
    load_model(cvae.D, dir, 'D')
    load_model(cvae.R, dir, 'R')
    

def save_model(model, root, model_name):
    if not os.path.isdir(root):
        os.mkdir(root)
    p = os.path.join(root, '{}.pkl'.format(model_name))
    torch.save(model.state_dict(), p)
    return p

def save_var(var, root, var_name):
    if not os.path.isdir(root):
        os.mkdir(root)
    with open( os.path.join(root, '{}.pickle'.format(var_name)) , 'wb') as f:
        pickle.dump(var, f)
        f.close()

    
def load_model(model, root, model_name):
    
    p = os.path.join(root, '{}.pkl'.format(model_name))
    model.load_state_dict(torch.load(p))
    